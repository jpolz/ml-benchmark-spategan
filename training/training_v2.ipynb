{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b083b3",
   "metadata": {},
   "source": [
    "## V2 of the training notebook for GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be0caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "\n",
    "from ml_benchmark_spategan.config import config\n",
    "from ml_benchmark_spategan.dataloader import dataloader\n",
    "from ml_benchmark_spategan.model.spagan2d import Generator, Discriminator, train_gan_step\n",
    "from ml_benchmark_spategan.visualization.plot_train import plot_adversarial_losses, plot_predictions, plot_predictions_grid\n",
    "\n",
    "from diffusers import UNet2DModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034de71",
   "metadata": {},
   "source": [
    "### Load configuration and initialize run directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b4c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find project base directory\n",
    "project_base = pathlib.Path(os.getcwd()).parent\n",
    "# load configuration\n",
    "cf = config.set_up_run(project_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5fe16b",
   "metadata": {},
   "source": [
    "### Build dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9421b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train, test_dataloader, cf = dataloader.build_dataloaders(cf)\n",
    "# dataloader_train, test_dataloader = dataloader.build_dummy_dataloaders()\n",
    "# update cf in run directory\n",
    "cf.save()\n",
    "# describe shapes of data\n",
    "print(\"Training data shapes:\")\n",
    "x_shape, y_shape = dataloader_train.dataset._get_shapes()\n",
    "print(f\"  x: {x_shape}\")\n",
    "print(f\"  y: {y_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c998347",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "match cf.model.architecture:\n",
    "    case \"spategan\":\n",
    "        print(\"Using SpaGAN architecture\")\n",
    "        # Initialize models\n",
    "        generator = Generator(cf.model).to(device)\n",
    "\n",
    "        # Print model summaries\n",
    "        print(\"Generator architecture:\")\n",
    "        summary(generator, input_size=(1, 15, 16, 16))\n",
    "    case \"diffusion_unet\":\n",
    "        print(\"Using Diffusion UNet architecture\")\n",
    "        generator = UNet2DModel(\n",
    "                sample_size=(128, 128),\n",
    "                in_channels=15+1,  # +1 == noise\n",
    "                out_channels=1,\n",
    "                layers_per_block=2,\n",
    "                block_out_channels=(64, 128, 128, 256),\n",
    "                down_block_types=(\"DownBlock2D\", \"DownBlock2D\", \"DownBlock2D\", \"AttnDownBlock2D\"),\n",
    "                up_block_types=(\"UpBlock2D\", \"AttnUpBlock2D\", \"UpBlock2D\", \"UpBlock2D\"),\n",
    "            ).to(device)\n",
    "        print(summary(generator, input_size=[(1, 16, 128, 128), (1,)], dtypes=[torch.float32, torch.long]))\n",
    "\n",
    "\n",
    "    case _:\n",
    "        raise ValueError(f\"Invalid option: {cf.model.architecture}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4720a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "discriminator = Discriminator(cf).to(device)\n",
    "print(\"\\nDiscriminator architecture:\")\n",
    "# Note: Discriminator takes (high_res_target, low_res_input)\n",
    "summary(discriminator, input_size=[(1, 1, 128, 128), (1, 15, 16, 16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41558533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move models to device\n",
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizers\n",
    "gen_opt = torch.optim.AdamW(\n",
    "    generator.parameters(), \n",
    "    lr=cf.training.learning_rate, \n",
    "    betas=(0.0, 0.999),\n",
    "    weight_decay=0.0001\n",
    ")\n",
    "\n",
    "disc_opt = torch.optim.AdamW(\n",
    "    discriminator.parameters(), \n",
    "    lr=cf.training.learning_rate, \n",
    "    betas=(0.0, 0.999),\n",
    "    weight_decay=0.0001\n",
    ")\n",
    "\n",
    "# For mixed precision training\n",
    "scaler = torch.amp.GradScaler('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for diffuser UNET, could later moved to dataloader.\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def upscale_nn(x):\n",
    "    # x: (15, 16, 16)\n",
    "    return F.interpolate(\n",
    "        x, \n",
    "        size=(128, 128),\n",
    "        mode=\"bilinear\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "def add_noise_channel(x):\n",
    "    # x: (B, 15, 128, 128)\n",
    "    noise = torch.randn(\n",
    "        x.size(0),      # batch\n",
    "        1,              # 1 noise channel\n",
    "        x.size(2),      # height = 128\n",
    "        x.size(3),      # width = 128\n",
    "        device=x.device # put noise on same device (GPU or CPU)\n",
    "    )\n",
    "\n",
    "    return torch.cat([x, noise], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d156f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN Training loop\n",
    "loss_gen_train = []\n",
    "loss_disc_train = []\n",
    "loss_gen_test = []\n",
    "\n",
    "print(f\"Starting GAN training for {cf.training.epochs} epochs...\")\n",
    "\n",
    "# Get a fixed batch for visualization\n",
    "val_iter = iter(test_dataloader)\n",
    "x_vis, y_vis = next(val_iter)\n",
    "x_vis, y_vis = x_vis.to(device), y_vis.to(device)\n",
    "if cf.model.architecture == \"diffusion_unet\":\n",
    "    x_vis = upscale_nn(x_vis)\n",
    "    x_vis = add_noise_channel(x_vis) # add noise to HR or LR?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(cf.training.epochs):\n",
    "    # Training phase\n",
    "    epoch_gen_losses = []\n",
    "    epoch_disc_losses = []\n",
    "    \n",
    "    for batch_idx, (x_batch, y_batch) in tqdm(enumerate(dataloader_train), total=len(dataloader_train)):\n",
    "        x_batch = x_batch.to(device)\n",
    "        x_batch_hr = upscale_nn(x_batch) # move to where it is needed, if needed\n",
    "        # during training, noise channel is added during train step\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        # zero timestep, for diffusion UNET.\n",
    "        timesteps = torch.zeros([x_batch.shape[0]]).to(device) # only for diffusion unet \n",
    "        \n",
    "        # Reshape y_batch to 2D for discriminator\n",
    "        y_batch_2d = y_batch.view(-1, 1, 128, 128)\n",
    "        \n",
    "        # Use the train_gan_step function from spagan2d\n",
    "        gen_loss, disc_loss = train_gan_step(\n",
    "            config=cf,\n",
    "            input_image=x_batch,\n",
    "            input_image_hr=x_batch_hr,\n",
    "            target=y_batch_2d,\n",
    "            step=epoch * len(dataloader_train) + batch_idx,\n",
    "            discriminator=discriminator,\n",
    "            generator=generator,\n",
    "            gen_opt=gen_opt,\n",
    "            disc_opt=disc_opt,\n",
    "            scaler=scaler,\n",
    "            criterion=criterion,\n",
    "            timesteps=timesteps\n",
    "        )\n",
    "        \n",
    "        epoch_gen_losses.append(gen_loss)\n",
    "        epoch_disc_losses.append(disc_loss)\n",
    "    \n",
    "    # Calculate average training losses\n",
    "    train_gen_loss = np.mean(epoch_gen_losses)\n",
    "    train_disc_loss = np.mean(epoch_disc_losses)\n",
    "    loss_gen_train.append(train_gen_loss)\n",
    "    loss_disc_train.append(train_disc_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    generator.eval()\n",
    "    test_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            x_batch_hr = upscale_nn(x_batch)\n",
    "            x_batch_hr = add_noise_channel(x_batch_hr) # add noise to HR or LR?\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            # zero timestep, for diffusion UNET.\n",
    "            timesteps = torch.zeros([x_batch.shape[0]]).to(device)\n",
    "            \n",
    "            with torch.amp.autocast('cuda'):\n",
    "                match cf.model.architecture:\n",
    "                    case \"spategan\":\n",
    "                        y_pred = generator(x_batch)\n",
    "                    case \"diffusion_unet\":\n",
    "                        y_pred = generator(x_batch_hr, timesteps).sample\n",
    "                        y_pred = torch.flatten(y_pred, start_dim=1)\n",
    "                loss = nn.L1Loss()(y_pred, y_batch)\n",
    "            \n",
    "            test_losses.append(loss.item())\n",
    "    \n",
    "    test_loss = np.mean(test_losses)\n",
    "    loss_gen_test.append(test_loss)\n",
    "    \n",
    "    # Print progress and plot\n",
    "    if (epoch + 1) % cf.logging.log_frequency == 0 or epoch == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f'Epoch {epoch+1}/{cf.training.epochs}')\n",
    "        print(f'  Generator Loss:     {train_gen_loss:.6f}')\n",
    "        print(f'  Discriminator Loss: {train_disc_loss:.6f}')\n",
    "        print(f'  Test Loss (L1):     {test_loss:.6f}')\n",
    "        \n",
    "        # Plot losses\n",
    "        plot_adversarial_losses(loss_gen_train, loss_disc_train, loss_gen_test, cf)\n",
    "        \n",
    "        \n",
    "    # Save checkpoint\n",
    "    if (epoch + 1) % cf.logging.checkpoint_frequency == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            'gen_optimizer_state_dict': gen_opt.state_dict(),\n",
    "            'disc_optimizer_state_dict': disc_opt.state_dict(),\n",
    "            'train_gen_loss': train_gen_loss,\n",
    "            'train_disc_loss': train_disc_loss,\n",
    "            'test_loss': test_loss,\n",
    "        }, f'{cf.logging.run_dir}/checkpoint_epoch_{epoch+1}.pt')\n",
    "        print(f'  Checkpoint saved')\n",
    "\n",
    "    if (epoch + 1) % cf.logging.map_frequency == 0:\n",
    "        # Visualize predictions\n",
    "        # plot_predictions(generator, x_vis.to(device), y_vis.to(device), cf, epoch + 1, num_samples=3)\n",
    "        g = torch.Generator(device=\"cpu\")\n",
    "        g.seed()  # uses system entropy\n",
    "        idx = torch.randint(0, x_vis.size(0), (1,), generator=g).item()\n",
    "        print('plotting', idx)\n",
    "        plot_predictions_grid(generator, x_vis, y_vis, cf, epoch + 1, device, sample_idx=idx)\n",
    "\n",
    "# Save final models\n",
    "torch.save({\n",
    "    'epoch': cf.training.epochs,\n",
    "    'generator_state_dict': generator.state_dict(),\n",
    "    'discriminator_state_dict': discriminator.state_dict(),\n",
    "    'gen_optimizer_state_dict': gen_opt.state_dict(),\n",
    "    'disc_optimizer_state_dict': disc_opt.state_dict(),\n",
    "}, f'{cf.logging.run_dir}/final_models.pt')\n",
    "\n",
    "print(f'\\nGAN training complete! Models saved to {cf.logging.run_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hinge loss test. --> not working\n",
    "\n",
    "\n",
    "\n",
    "# label smoothing test --> geht, aber disc. stays same\n",
    "\n",
    "# no noise on disc input: --> same\n",
    "\n",
    "# random sigma -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66176c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9118cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab1efff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-benchmark-spategan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
