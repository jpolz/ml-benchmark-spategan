{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b083b3",
   "metadata": {},
   "source": [
    "## V2 of the training notebook for GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be0caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "\n",
    "from ml_benchmark_spategan.config import config\n",
    "from ml_benchmark_spategan.dataloader import dataloader\n",
    "from ml_benchmark_spategan.model.spagan2d import Generator, Discriminator, train_gan_step\n",
    "from ml_benchmark_spategan.visualization.plot_train import plot_adversarial_losses, plot_predictions\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034de71",
   "metadata": {},
   "source": [
    "### Load configuration and initialize run directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b4c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find project base directory\n",
    "project_base = pathlib.Path(os.getcwd()).parent\n",
    "# load configuration\n",
    "cf = config.set_up_run(project_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5fe16b",
   "metadata": {},
   "source": [
    "### Build dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9421b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader_train, test_dataloader, cf = dataloader.build_dataloaders(cf)\n",
    "dataloader_train, test_dataloader = dataloader.build_dummy_dataloaders()\n",
    "# update cf in run directory\n",
    "cf.save()\n",
    "# describe shapes of data\n",
    "print(\"Training data shapes:\")\n",
    "x_shape, y_shape = dataloader_train.dataset._get_shapes()\n",
    "print(f\"  x: {x_shape}\")\n",
    "print(f\"  y: {y_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c998347",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize models\n",
    "generator = Generator(cf.model).to(device)\n",
    "\n",
    "# Print model summaries\n",
    "print(\"Generator architecture:\")\n",
    "summary(generator, input_size=(1, 15, 16, 16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4720a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "discriminator = Discriminator(cf).to(device)\n",
    "print(\"\\nDiscriminator architecture:\")\n",
    "# Note: Discriminator takes (high_res_target, low_res_input)\n",
    "summary(discriminator, input_size=[(1, 1, 128, 128), (1, 15, 16, 16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41558533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move models to device\n",
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizers\n",
    "gen_opt = torch.optim.AdamW(\n",
    "    generator.parameters(), \n",
    "    lr=cf.training.learning_rate, \n",
    "    betas=(0.0, 0.999),\n",
    "    weight_decay=0.0001\n",
    ")\n",
    "\n",
    "disc_opt = torch.optim.AdamW(\n",
    "    discriminator.parameters(), \n",
    "    lr=cf.training.learning_rate, \n",
    "    betas=(0.0, 0.999),\n",
    "    weight_decay=0.0001\n",
    ")\n",
    "\n",
    "# For mixed precision training\n",
    "scaler = torch.amp.GradScaler('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d156f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN Training loop\n",
    "loss_gen_train = []\n",
    "loss_disc_train = []\n",
    "loss_gen_test = []\n",
    "\n",
    "print(f\"Starting GAN training for {cf.training.epochs} epochs...\")\n",
    "\n",
    "# Get a fixed batch for visualization\n",
    "val_iter = iter(test_dataloader)\n",
    "x_vis, y_vis = next(val_iter)\n",
    "\n",
    "for epoch in range(cf.training.epochs):\n",
    "    # Training phase\n",
    "    epoch_gen_losses = []\n",
    "    epoch_disc_losses = []\n",
    "    \n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(dataloader_train):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        # Reshape y_batch to 2D for discriminator\n",
    "        y_batch_2d = y_batch.view(-1, 1, 128, 128)\n",
    "        \n",
    "        # Use the train_gan_step function from spagan2d\n",
    "        gen_loss, disc_loss = train_gan_step(\n",
    "            config=cf,\n",
    "            input_image=x_batch,\n",
    "            target=y_batch_2d,\n",
    "            step=epoch * len(dataloader_train) + batch_idx,\n",
    "            discriminator=discriminator,\n",
    "            generator=generator,\n",
    "            gen_opt=gen_opt,\n",
    "            disc_opt=disc_opt,\n",
    "            scaler=scaler,\n",
    "            criterion=criterion\n",
    "        )\n",
    "        \n",
    "        epoch_gen_losses.append(gen_loss)\n",
    "        epoch_disc_losses.append(disc_loss)\n",
    "    \n",
    "    # Calculate average training losses\n",
    "    train_gen_loss = np.mean(epoch_gen_losses)\n",
    "    train_disc_loss = np.mean(epoch_disc_losses)\n",
    "    loss_gen_train.append(train_gen_loss)\n",
    "    loss_disc_train.append(train_disc_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    generator.eval()\n",
    "    test_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            with torch.amp.autocast('cuda'):\n",
    "                y_pred = generator(x_batch)\n",
    "                loss = nn.L1Loss()(y_pred, y_batch)\n",
    "            \n",
    "            test_losses.append(loss.item())\n",
    "    \n",
    "    test_loss = np.mean(test_losses)\n",
    "    loss_gen_test.append(test_loss)\n",
    "    \n",
    "    # Print progress and plot\n",
    "    if (epoch + 1) % cf.logging.save_frequency == 0 or epoch == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f'Epoch {epoch+1}/{cf.training.epochs}')\n",
    "        print(f'  Generator Loss:     {train_gen_loss:.6f}')\n",
    "        print(f'  Discriminator Loss: {train_disc_loss:.6f}')\n",
    "        print(f'  Test Loss (L1):     {test_loss:.6f}')\n",
    "        \n",
    "        # Plot losses\n",
    "        plot_adversarial_losses(loss_gen_train, loss_disc_train, loss_gen_test, cf)\n",
    "        \n",
    "        \n",
    "    # Save checkpoint\n",
    "    if (epoch + 1) % cf.logging.checkpoint_frequency == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            'gen_optimizer_state_dict': gen_opt.state_dict(),\n",
    "            'disc_optimizer_state_dict': disc_opt.state_dict(),\n",
    "            'train_gen_loss': train_gen_loss,\n",
    "            'train_disc_loss': train_disc_loss,\n",
    "            'test_loss': test_loss,\n",
    "        }, f'{cf.logging.run_dir}/checkpoint_epoch_{epoch+1}.pt')\n",
    "        print(f'  Checkpoint saved')\n",
    "\n",
    "    if (epoch + 1) % cf.logging.map_frequency == 0:\n",
    "        # Visualize predictions\n",
    "        plot_predictions(generator, x_vis.to(device), y_vis.to(device), cf, epoch + 1, num_samples=3)\n",
    "\n",
    "# Save final models\n",
    "torch.save({\n",
    "    'epoch': cf.training.epochs,\n",
    "    'generator_state_dict': generator.state_dict(),\n",
    "    'discriminator_state_dict': discriminator.state_dict(),\n",
    "    'gen_optimizer_state_dict': gen_opt.state_dict(),\n",
    "    'disc_optimizer_state_dict': disc_opt.state_dict(),\n",
    "}, f'{cf.logging.run_dir}/final_models.pt')\n",
    "\n",
    "print(f'\\nGAN training complete! Models saved to {cf.logging.run_dir}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-benchmark-spategan (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
