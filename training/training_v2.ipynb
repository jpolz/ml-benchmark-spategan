{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b083b3",
   "metadata": {},
   "source": [
    "## V2 of the training notebook for GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be0caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "\n",
    "from ml_benchmark_spategan.config import config\n",
    "from ml_benchmark_spategan.dataloader import dataloader\n",
    "from ml_benchmark_spategan.model.spagan2d import Generator, Discriminator, train_gan_step\n",
    "from ml_benchmark_spategan.visualization.plot_train import plot_adversarial_losses, plot_predictions, plot_diagnostic_history\n",
    "from ml_benchmark_spategan.utils.denormalize import predictions_to_xarray\n",
    "\n",
    "from diffusers import UNet2DModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Import diagnostics\n",
    "import sys\n",
    "sys.path.append('../evaluation')\n",
    "import diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034de71",
   "metadata": {},
   "source": [
    "### Load configuration and initialize run directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b4c769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 00:24:37 - ml_benchmark_spategan.config.config - INFO - Configuration:\n",
      "data:\n",
      "  domain: SA\n",
      "  training_experiment: ESD_pseudo_reality\n",
      "  data_path: /bg/fast/aihydromet/cordexbench/\n",
      "  var_target: tasmax\n",
      "  normalization: minus1_to_plus1\n",
      "  num_workers: 4\n",
      "training:\n",
      "  batch_size: 32\n",
      "  epochs: 400\n",
      "  batches_per_epoch: 40\n",
      "  generator:\n",
      "    learning_rate: 0.0001\n",
      "    optimizer: AdamW\n",
      "    scheduler: null\n",
      "    beta1: 0.0\n",
      "    beta2: 0.999\n",
      "    weight_decay: 0.0001\n",
      "  discriminator:\n",
      "    learning_rate: 0.0001\n",
      "    optimizer: AdamW\n",
      "    scheduler: null\n",
      "    beta1: 0.0\n",
      "    beta2: 0.999\n",
      "    weight_decay: 0.0001\n",
      "  early_stopping: true\n",
      "  patience: 10\n",
      "  checkpoint_dir: checkpoints\n",
      "  loss_weights:\n",
      "    l1: 1.0\n",
      "    gan: 0.1\n",
      "model:\n",
      "  generator_architecture: diffusion_unet\n",
      "  discriminator_architecture: spagan\n",
      "  filter_size: 96\n",
      "  n_input_channels: 15\n",
      "  n_output_channels: 1\n",
      "  dropout_seed: 42\n",
      "  dropout_ratio: 0.2\n",
      "evaluation:\n",
      "  metrics:\n",
      "  - rmse\n",
      "  output_dir: results\n",
      "logging:\n",
      "  level: INFO\n",
      "  log_dir: logs\n",
      "  wandb: false\n",
      "  log_frequency: 1\n",
      "  checkpoint_frequency: 20\n",
      "  map_frequency: 1\n",
      "  diagnostic_frequency: 1\n",
      "\n",
      "2025-12-12 00:24:37 - ml_benchmark_spategan.config.config - INFO - Run ID: 20251212_0024_3xd0915i\n",
      "2025-12-12 00:24:37 - ml_benchmark_spategan.config.config - INFO - Configuration saved to: /bg/fast/env_polz-j/uvprojects/ml-benchmark-spategan/runs/20251212_0024_3xd0915i/config.yaml\n",
      "2025-12-12 00:24:37 - ml_benchmark_spategan.config.config - INFO - Run directory set up at: /bg/fast/env_polz-j/uvprojects/ml-benchmark-spategan/runs/20251212_0024_3xd0915i\n"
     ]
    }
   ],
   "source": [
    "# find project base directory\n",
    "project_base = pathlib.Path(os.getcwd()).parent\n",
    "# load configuration\n",
    "cf = config.set_up_run(project_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5fe16b",
   "metadata": {},
   "source": [
    "### Build dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9421b773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 00:24:39 - ml_benchmark_spategan.config.config - INFO - Configuration saved to: /bg/fast/env_polz-j/uvprojects/ml-benchmark-spategan/runs/20251212_0024_3xd0915i/config.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes:\n",
      "  x: torch.Size([15, 16, 16])\n",
      "  y: torch.Size([16384])\n"
     ]
    }
   ],
   "source": [
    "dataloader_train, test_dataloader, cf, norm_params = dataloader.build_dataloaders(cf)\n",
    "# dataloader_train, test_dataloader = dataloader.build_dummy_dataloaders()\n",
    "# update cf in run directory\n",
    "cf.save()\n",
    "# describe shapes of data\n",
    "print(\"Training data shapes:\")\n",
    "x_shape, y_shape = dataloader_train.dataset._get_shapes()\n",
    "print(f\"  x: {x_shape}\")\n",
    "print(f\"  y: {y_shape}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5855bdd6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "class denorm_y:\n",
    "    def __init__(self, y_min, y_max):\n",
    "        self.y_min = y_min\n",
    "        self.y_max = y_max\n",
    "\n",
    "    def __call__(self, y_norm):\n",
    "        y_denorm = (y_norm + 1) / 2 * (self.y_max - self.y_min) + self.y_min\n",
    "        return y_denorm\n",
    "\n",
    "denorm_y_fn = denorm_y(cf.data.y_min, cf.data.y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c998347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Diffusion UNet architecture\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "UNet2DModel                                   [1, 1, 128, 128]          --\n",
      "├─Timesteps: 1-1                              [1, 64]                   --\n",
      "├─TimestepEmbedding: 1-2                      [1, 256]                  --\n",
      "│    └─Linear: 2-1                            [1, 256]                  16,640\n",
      "│    └─SiLU: 2-2                              [1, 256]                  --\n",
      "│    └─Linear: 2-3                            [1, 256]                  65,792\n",
      "├─Conv2d: 1-3                                 [1, 64, 128, 128]         9,280\n",
      "├─ModuleList: 1-4                             --                        --\n",
      "│    └─DownBlock2D: 2-4                       [1, 64, 64, 64]           --\n",
      "│    │    └─ModuleList: 3-1                   --                        181,120\n",
      "│    │    └─ModuleList: 3-2                   --                        36,928\n",
      "│    └─DownBlock2D: 2-5                       [1, 128, 32, 32]          --\n",
      "│    │    └─ModuleList: 3-3                   --                        591,616\n",
      "│    │    └─ModuleList: 3-4                   --                        147,584\n",
      "│    └─DownBlock2D: 2-6                       [1, 128, 16, 16]          --\n",
      "│    │    └─ModuleList: 3-5                   --                        657,152\n",
      "│    │    └─ModuleList: 3-6                   --                        147,584\n",
      "│    └─AttnDownBlock2D: 2-7                   [1, 256, 16, 16]          --\n",
      "│    │    └─ModuleList: 3-9                   --                        (recursive)\n",
      "│    │    └─ModuleList: 3-10                  --                        (recursive)\n",
      "│    │    └─ModuleList: 3-9                   --                        (recursive)\n",
      "│    │    └─ModuleList: 3-10                  --                        (recursive)\n",
      "├─UNetMidBlock2D: 1-5                         [1, 256, 16, 16]          --\n",
      "│    └─ModuleList: 2-10                       --                        (recursive)\n",
      "│    │    └─ResnetBlock2D: 3-11               [1, 256, 16, 16]          1,246,976\n",
      "│    └─ModuleList: 2-9                        --                        --\n",
      "│    │    └─Attention: 3-12                   [1, 256, 16, 16]          263,680\n",
      "│    └─ModuleList: 2-10                       --                        (recursive)\n",
      "│    │    └─ResnetBlock2D: 3-13               [1, 256, 16, 16]          1,246,976\n",
      "├─ModuleList: 1-6                             --                        --\n",
      "│    └─UpBlock2D: 2-11                        [1, 256, 32, 32]          --\n",
      "│    │    └─ModuleList: 3-14                  --                        5,577,984\n",
      "│    │    └─ModuleList: 3-15                  --                        590,080\n",
      "│    └─AttnUpBlock2D: 2-12                    [1, 128, 64, 64]          --\n",
      "│    │    └─ModuleList: 3-20                  --                        (recursive)\n",
      "│    │    └─ModuleList: 3-21                  --                        (recursive)\n",
      "│    │    └─ModuleList: 3-20                  --                        (recursive)\n",
      "│    │    └─ModuleList: 3-21                  --                        (recursive)\n",
      "│    │    └─ModuleList: 3-20                  --                        (recursive)\n",
      "│    │    └─ModuleList: 3-21                  --                        (recursive)\n",
      "│    │    └─ModuleList: 3-22                  --                        147,584\n",
      "│    └─UpBlock2D: 2-13                        [1, 128, 128, 128]        --\n",
      "│    │    └─ModuleList: 3-23                  --                        1,445,504\n",
      "│    │    └─ModuleList: 3-24                  --                        147,584\n",
      "│    └─UpBlock2D: 2-14                        [1, 64, 128, 128]         --\n",
      "│    │    └─ModuleList: 3-25                  --                        448,512\n",
      "├─GroupNorm: 1-7                              [1, 64, 128, 128]         128\n",
      "├─SiLU: 1-8                                   [1, 64, 128, 128]         --\n",
      "├─Conv2d: 1-9                                 [1, 1, 128, 128]          577\n",
      "===============================================================================================\n",
      "Total params: 17,619,009\n",
      "Trainable params: 17,619,009\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 25.48\n",
      "===============================================================================================\n",
      "Input size (MB): 1.05\n",
      "Forward/backward pass size (MB): 448.69\n",
      "Params size (MB): 70.48\n",
      "Estimated Total Size (MB): 520.22\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "match cf.model.generator_architecture:\n",
    "    case \"spategan\":\n",
    "        print(\"Using SpaGAN architecture\")\n",
    "        # Initialize models\n",
    "        generator = Generator(cf.model).to(device)\n",
    "\n",
    "        # Print model summaries\n",
    "        print(\"Generator architecture:\")\n",
    "        summary(generator, input_size=(1, 15, 16, 16))\n",
    "    case \"diffusion_unet\":\n",
    "        print(\"Using Diffusion UNet architecture\")\n",
    "        generator = UNet2DModel(\n",
    "                sample_size=(128, 128),\n",
    "                in_channels=15+1,  # +1 == noise\n",
    "                out_channels=1,\n",
    "                layers_per_block=2,\n",
    "                block_out_channels=(64, 128, 128, 256),\n",
    "                down_block_types=(\"DownBlock2D\", \"DownBlock2D\", \"DownBlock2D\", \"AttnDownBlock2D\"),\n",
    "                up_block_types=(\"UpBlock2D\", \"AttnUpBlock2D\", \"UpBlock2D\", \"UpBlock2D\"),\n",
    "            ).to(device)\n",
    "        print(summary(generator, input_size=[(1, 16, 128, 128), (1,)], dtypes=[torch.float32, torch.long]))\n",
    "\n",
    "\n",
    "    case _:\n",
    "        raise ValueError(f\"Invalid option: {cf.model.generator_architecture}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21503eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SpaGAN Discriminator\n",
      "\n",
      "Discriminator architecture:\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Discriminator                            [1, 1, 4, 4]              --\n",
      "├─ResidualBlock2D: 1-1                   [1, 128, 128, 128]        --\n",
      "│    └─Conv2d: 2-1                       [1, 128, 128, 128]        1,152\n",
      "│    └─ReLU: 2-2                         [1, 128, 128, 128]        --\n",
      "│    └─Conv2d: 2-3                       [1, 128, 128, 128]        147,456\n",
      "│    └─Conv2d: 2-4                       [1, 128, 128, 128]        128\n",
      "│    └─InstanceNorm2d: 2-5               [1, 128, 128, 128]        --\n",
      "│    └─ReLU: 2-6                         [1, 128, 128, 128]        --\n",
      "├─ResidualBlock2D: 1-2                   [1, 128, 64, 64]          --\n",
      "│    └─Conv2d: 2-7                       [1, 128, 64, 64]          147,456\n",
      "│    └─InstanceNorm2d: 2-8               [1, 128, 64, 64]          --\n",
      "│    └─ReLU: 2-9                         [1, 128, 64, 64]          --\n",
      "│    └─Conv2d: 2-10                      [1, 128, 64, 64]          147,456\n",
      "│    └─InstanceNorm2d: 2-11              [1, 128, 64, 64]          --\n",
      "│    └─Conv2d: 2-12                      [1, 128, 64, 64]          16,384\n",
      "│    └─InstanceNorm2d: 2-13              [1, 128, 64, 64]          --\n",
      "│    └─ReLU: 2-14                        [1, 128, 64, 64]          --\n",
      "├─ResidualBlock2D: 1-3                   [1, 128, 32, 32]          --\n",
      "│    └─Conv2d: 2-15                      [1, 128, 32, 32]          147,456\n",
      "│    └─InstanceNorm2d: 2-16              [1, 128, 32, 32]          --\n",
      "│    └─ReLU: 2-17                        [1, 128, 32, 32]          --\n",
      "│    └─Conv2d: 2-18                      [1, 128, 32, 32]          147,456\n",
      "│    └─InstanceNorm2d: 2-19              [1, 128, 32, 32]          --\n",
      "│    └─Conv2d: 2-20                      [1, 128, 32, 32]          16,384\n",
      "│    └─InstanceNorm2d: 2-21              [1, 128, 32, 32]          --\n",
      "│    └─ReLU: 2-22                        [1, 128, 32, 32]          --\n",
      "├─ResidualBlock2D: 1-4                   [1, 64, 16, 16]           --\n",
      "│    └─Conv2d: 2-23                      [1, 64, 16, 16]           73,728\n",
      "│    └─InstanceNorm2d: 2-24              [1, 64, 16, 16]           --\n",
      "│    └─ReLU: 2-25                        [1, 64, 16, 16]           --\n",
      "│    └─Conv2d: 2-26                      [1, 64, 16, 16]           36,864\n",
      "│    └─InstanceNorm2d: 2-27              [1, 64, 16, 16]           --\n",
      "│    └─Conv2d: 2-28                      [1, 64, 16, 16]           8,192\n",
      "│    └─InstanceNorm2d: 2-29              [1, 64, 16, 16]           --\n",
      "│    └─ReLU: 2-30                        [1, 64, 16, 16]           --\n",
      "├─ResidualBlock2D: 1-5                   [1, 64, 8, 8]             --\n",
      "│    └─Conv2d: 2-31                      [1, 64, 8, 8]             36,864\n",
      "│    └─InstanceNorm2d: 2-32              [1, 64, 8, 8]             --\n",
      "│    └─ReLU: 2-33                        [1, 64, 8, 8]             --\n",
      "│    └─Conv2d: 2-34                      [1, 64, 8, 8]             36,864\n",
      "│    └─InstanceNorm2d: 2-35              [1, 64, 8, 8]             --\n",
      "│    └─Conv2d: 2-36                      [1, 64, 8, 8]             4,096\n",
      "│    └─InstanceNorm2d: 2-37              [1, 64, 8, 8]             --\n",
      "│    └─ReLU: 2-38                        [1, 64, 8, 8]             --\n",
      "├─ResidualBlock2D: 1-6                   [1, 64, 16, 16]           --\n",
      "│    └─Conv2d: 2-39                      [1, 64, 16, 16]           8,640\n",
      "│    └─ReLU: 2-40                        [1, 64, 16, 16]           --\n",
      "│    └─Conv2d: 2-41                      [1, 64, 16, 16]           36,864\n",
      "│    └─Conv2d: 2-42                      [1, 64, 16, 16]           960\n",
      "│    └─InstanceNorm2d: 2-43              [1, 64, 16, 16]           --\n",
      "│    └─ReLU: 2-44                        [1, 64, 16, 16]           --\n",
      "├─ResidualBlock2D: 1-7                   [1, 32, 8, 8]             --\n",
      "│    └─Conv2d: 2-45                      [1, 32, 8, 8]             18,432\n",
      "│    └─ReLU: 2-46                        [1, 32, 8, 8]             --\n",
      "│    └─Conv2d: 2-47                      [1, 32, 8, 8]             9,216\n",
      "│    └─Conv2d: 2-48                      [1, 32, 8, 8]             2,048\n",
      "│    └─InstanceNorm2d: 2-49              [1, 32, 8, 8]             --\n",
      "│    └─ReLU: 2-50                        [1, 32, 8, 8]             --\n",
      "├─ResidualBlock2D: 1-8                   [1, 64, 4, 4]             --\n",
      "│    └─Conv2d: 2-51                      [1, 64, 4, 4]             55,296\n",
      "│    └─InstanceNorm2d: 2-52              [1, 64, 4, 4]             --\n",
      "│    └─ReLU: 2-53                        [1, 64, 4, 4]             --\n",
      "│    └─Conv2d: 2-54                      [1, 64, 4, 4]             36,864\n",
      "│    └─InstanceNorm2d: 2-55              [1, 64, 4, 4]             --\n",
      "│    └─Conv2d: 2-56                      [1, 64, 4, 4]             6,144\n",
      "│    └─InstanceNorm2d: 2-57              [1, 64, 4, 4]             --\n",
      "│    └─ReLU: 2-58                        [1, 64, 4, 4]             --\n",
      "├─Sequential: 1-9                        [1, 1, 4, 4]              --\n",
      "│    └─Conv2d: 2-59                      [1, 1, 4, 4]              577\n",
      "==========================================================================================\n",
      "Total params: 1,142,977\n",
      "Trainable params: 1,142,977\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 4.08\n",
      "==========================================================================================\n",
      "Input size (MB): 0.08\n",
      "Forward/backward pass size (MB): 67.02\n",
      "Params size (MB): 4.57\n",
      "Estimated Total Size (MB): 71.67\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "if cf.model.discriminator_architecture == \"unet\":\n",
    "    print(\"Using UNet2DModel as discriminator\")\n",
    "    discriminator = UNet2DModel(\n",
    "                    sample_size=(128, 128),\n",
    "                    in_channels=2,  # +1 == noise\n",
    "                    out_channels=1,\n",
    "                    layers_per_block=2,\n",
    "                    block_out_channels=(32, 64, 128),\n",
    "                    down_block_types=(\"DownBlock2D\", \"DownBlock2D\", \"AttnDownBlock2D\"),\n",
    "                    up_block_types=(\"UpBlock2D\", \"AttnUpBlock2D\", \"UpBlock2D\"),\n",
    "                ).to(device)\n",
    "    print(summary(discriminator, input_size=[(1, 2, 128, 128), (1,)], dtypes=[torch.float32, torch.long]))\n",
    "elif cf.model.discriminator_architecture == \"spagan\":\n",
    "    print(\"Using SpaGAN Discriminator\")\n",
    "    discriminator = Discriminator(cf).to(device)\n",
    "    print(\"\\nDiscriminator architecture:\")\n",
    "    # Note: Discriminator takes (high_res_target, low_res_input)\n",
    "    print(summary(discriminator, input_size=[(1, 1, 128, 128), (1, 15, 16, 16)]))\n",
    "else:\n",
    "    raise ValueError(f\"Invalid option: {cf.model.discriminator_architecture}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41558533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move models to device\n",
    "generator = generator.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizers\n",
    "gen_opt = torch.optim.AdamW(\n",
    "    generator.parameters(), \n",
    "    lr=cf.training.generator.learning_rate, \n",
    "    betas=(cf.training.generator.beta1, cf.training.generator.beta2), # todo: try with momentum\n",
    "    weight_decay=cf.training.generator.weight_decay\n",
    ")\n",
    "\n",
    "disc_opt = torch.optim.AdamW(\n",
    "    discriminator.parameters(), \n",
    "    lr=cf.training.discriminator.learning_rate, \n",
    "    betas=(cf.training.discriminator.beta1, cf.training.discriminator.beta2), # not using momentum on the disc since it can lead to instability\n",
    "    weight_decay=cf.training.discriminator.weight_decay\n",
    ")\n",
    "\n",
    "# For mixed precision training\n",
    "scaler = torch.amp.GradScaler('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4e4b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for diffuser UNET, could later moved to dataloader.\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def upscale_nn(x):\n",
    "    # x: (15, 16, 16)\n",
    "    return F.interpolate(\n",
    "        x, \n",
    "        size=(128, 128),\n",
    "        mode=\"bilinear\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "def add_noise_channel(x):\n",
    "    # x: (B, 15, 128, 128)\n",
    "    noise = torch.randn(\n",
    "        x.size(0),      # batch\n",
    "        1,              # 1 noise channel\n",
    "        x.size(2),      # height = 128\n",
    "        x.size(3),      # width = 128\n",
    "        device=x.device # put noise on same device (GPU or CPU)\n",
    "    )\n",
    "\n",
    "    return torch.cat([x, noise], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d156f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/400\n",
      "  Generator Loss:     0.158868\n",
      "  Discriminator Loss: 1.190579\n",
      "  Test Loss (L1):     0.105518\n",
      "  Computing diagnostics...\n"
     ]
    }
   ],
   "source": [
    "# GAN Training loop\n",
    "loss_gen_train = []\n",
    "loss_disc_train = []\n",
    "loss_gen_test = []\n",
    "\n",
    "# Store diagnostics\n",
    "diagnostic_history = {\n",
    "    'rmse': [],\n",
    "    'bias_mean': [],\n",
    "    'epochs': []\n",
    "}\n",
    "\n",
    "print(f\"Starting GAN training for {cf.training.epochs} epochs...\")\n",
    "\n",
    "# Get a fixed batch for visualization\n",
    "val_iter = iter(test_dataloader)\n",
    "x_vis, y_vis = next(val_iter)\n",
    "x_vis, y_vis = x_vis.to(device), y_vis.to(device)\n",
    "if cf.model.generator_architecture == \"diffusion_unet\":\n",
    "    x_vis = upscale_nn(x_vis)\n",
    "    x_vis = add_noise_channel(x_vis) # add noise to HR or LR?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(cf.training.epochs):\n",
    "    # Training phase\n",
    "    epoch_gen_losses = []\n",
    "    epoch_disc_losses = []\n",
    "    \n",
    "    for batch_idx, (x_batch, y_batch) in tqdm(enumerate(dataloader_train), total=len(dataloader_train)):\n",
    "        x_batch = x_batch.to(device)\n",
    "        x_batch_hr = upscale_nn(x_batch) # move to where it is needed, if needed\n",
    "        # during training, noise channel is added during train step\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        # zero timestep, for diffusion UNET.\n",
    "        timesteps = torch.zeros([x_batch.shape[0]]).to(device) # only for diffusion unet \n",
    "        \n",
    "        # Reshape y_batch to 2D for discriminator\n",
    "        y_batch_2d = y_batch.view(-1, 1, 128, 128)\n",
    "        \n",
    "        # Use the train_gan_step function from spagan2d\n",
    "        gen_loss, disc_loss = train_gan_step(\n",
    "            config=cf,\n",
    "            input_image=x_batch,\n",
    "            input_image_hr=x_batch_hr,\n",
    "            target=y_batch_2d,\n",
    "            step=epoch * len(dataloader_train) + batch_idx,\n",
    "            discriminator=discriminator,\n",
    "            generator=generator,\n",
    "            gen_opt=gen_opt,\n",
    "            disc_opt=disc_opt,\n",
    "            scaler=scaler,\n",
    "            criterion=criterion,\n",
    "            timesteps=timesteps,\n",
    "            loss_weights=cf.training.loss_weights,\n",
    "            condition_separate_channels=True,\n",
    "        )\n",
    "        \n",
    "        epoch_gen_losses.append(gen_loss)\n",
    "        epoch_disc_losses.append(disc_loss)\n",
    "    \n",
    "    # Calculate average training losses\n",
    "    train_gen_loss = np.mean(epoch_gen_losses)\n",
    "    train_disc_loss = np.mean(epoch_disc_losses)\n",
    "    loss_gen_train.append(train_gen_loss)\n",
    "    loss_disc_train.append(train_disc_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    generator.eval()\n",
    "    test_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            x_batch_hr = upscale_nn(x_batch)\n",
    "            x_batch_hr = add_noise_channel(x_batch_hr) # add noise to HR or LR?\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            # zero timestep, for diffusion UNET.\n",
    "            timesteps = torch.zeros([x_batch.shape[0]]).to(device)\n",
    "            \n",
    "            with torch.amp.autocast('cuda'):\n",
    "                match cf.model.generator_architecture:\n",
    "                    case \"spategan\":\n",
    "                        y_pred = generator(x_batch)\n",
    "                    case \"diffusion_unet\":\n",
    "                        y_pred = generator(x_batch_hr, timesteps).sample\n",
    "                        y_pred = torch.flatten(y_pred, start_dim=1)\n",
    "                loss = nn.L1Loss()(y_pred, y_batch)\n",
    "            \n",
    "            test_losses.append(loss.item())\n",
    "    \n",
    "    test_loss = np.mean(test_losses)\n",
    "    loss_gen_test.append(test_loss)\n",
    "    \n",
    "    # Print progress and plot\n",
    "    if (epoch + 1) % cf.logging.log_frequency == 0 or epoch == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f'Epoch {epoch+1}/{cf.training.epochs}')\n",
    "        print(f'  Generator Loss:     {train_gen_loss:.6f}')\n",
    "        print(f'  Discriminator Loss: {train_disc_loss:.6f}')\n",
    "        print(f'  Test Loss (L1):     {test_loss:.6f}')\n",
    "        \n",
    "        # Plot losses\n",
    "        plot_adversarial_losses(loss_gen_train, loss_disc_train, loss_gen_test, cf)\n",
    "    \n",
    "    # Compute diagnostics\n",
    "    if (epoch + 1) % cf.logging.diagnostic_frequency == 0:\n",
    "        print(f'  Computing diagnostics...')\n",
    "        generator.eval()\n",
    "        \n",
    "        # Collect all test predictions\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in test_dataloader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                x_batch_hr = upscale_nn(x_batch)\n",
    "                x_batch_hr = add_noise_channel(x_batch_hr)\n",
    "                \n",
    "                timesteps = torch.zeros([x_batch.shape[0]]).to(device)\n",
    "                \n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    match cf.model.generator_architecture:\n",
    "                        case \"spategan\":\n",
    "                            y_pred = generator(x_batch)\n",
    "                        case \"diffusion_unet\":\n",
    "                            y_pred = generator(x_batch_hr, timesteps).sample\n",
    "                            y_pred = torch.flatten(y_pred, start_dim=1)\n",
    "                \n",
    "                all_preds.append(y_pred.cpu())\n",
    "                all_targets.append(y_batch.cpu())\n",
    "        \n",
    "        # Concatenate all batches\n",
    "        y_pred_all = torch.cat(all_preds, dim=0)\n",
    "        y_true_all = torch.cat(all_targets, dim=0)\n",
    "        \n",
    "        # Convert to xarray with denormalization\n",
    "        pred_ds, true_ds = predictions_to_xarray(\n",
    "            y_pred_all, y_true_all, norm_params, var_name=cf.data.var_target\n",
    "        )\n",
    "        \n",
    "        # Compute diagnostics\n",
    "        rmse = diagnostics.rmse(true_ds, pred_ds, var=cf.data.var_target, dim='time')\n",
    "        bias_mean = diagnostics.bias_index(true_ds, pred_ds, \n",
    "                                          index_fn=lambda x, **kw: x[cf.data.var_target].mean('time'))\n",
    "        diagnostic_history['rmse'].append(rmse[cf.data.var_target].mean().values.item())\n",
    "        diagnostic_history['bias_mean'].append(bias_mean.mean().values.item())\n",
    "        diagnostic_history['epochs'].append(epoch + 1)\n",
    "        \n",
    "        print(f'  RMSE (spatial mean): {diagnostic_history[\"rmse\"][-1]:.4f}')\n",
    "        print(f'  Bias Mean (spatial mean): {diagnostic_history[\"bias_mean\"][-1]:.4f}')\n",
    "        \n",
    "    # Save checkpoint\n",
    "    if (epoch + 1) % cf.logging.checkpoint_frequency == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            'gen_optimizer_state_dict': gen_opt.state_dict(),\n",
    "            'disc_optimizer_state_dict': disc_opt.state_dict(),\n",
    "            'train_gen_loss': train_gen_loss,\n",
    "            'train_disc_loss': train_disc_loss,\n",
    "            'test_loss': test_loss,\n",
    "            'diagnostic_history': diagnostic_history,\n",
    "        }, f'{cf.logging.run_dir}/checkpoint_epoch_{epoch+1}.pt')\n",
    "        print(f'  Checkpoint saved')\n",
    "\n",
    "    if (epoch + 1) % cf.logging.map_frequency == 0:\n",
    "        # Visualize predictions with denormalization\n",
    "        g = torch.Generator(device=\"cpu\")\n",
    "        g.seed()  # uses system entropy\n",
    "        idx = torch.randint(0, x_vis.size(0), (1,), generator=g).item()\n",
    "        print(f'  Plotting sample {idx}')\n",
    "        plot_predictions(generator, x_vis, y_vis, cf, epoch + 1, device, \n",
    "                        sample_idx=idx, norm_params=norm_params)\n",
    "\n",
    "# Save final models\n",
    "torch.save({\n",
    "    'epoch': cf.training.epochs,\n",
    "    'generator_state_dict': generator.state_dict(),\n",
    "    'discriminator_state_dict': discriminator.state_dict(),\n",
    "    'gen_optimizer_state_dict': gen_opt.state_dict(),\n",
    "    'disc_optimizer_state_dict': disc_opt.state_dict(),\n",
    "    'diagnostic_history': diagnostic_history,\n",
    "}, f'{cf.logging.run_dir}/final_models.pt')\n",
    "\n",
    "print(f'\\nGAN training complete! Models saved to {cf.logging.run_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hinge loss test. --> not working\n",
    "\n",
    "\n",
    "\n",
    "# label smoothing test --> geht, aber disc. stays same\n",
    "\n",
    "# no noise on disc input: --> same\n",
    "\n",
    "# random sigma -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680b1e2",
   "metadata": {},
   "source": [
    "### Plot Diagnostic History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cfab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diagnostic_history(diagnostic_history, cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66176c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9118cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab1efff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-benchmark-spategan (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
