# Data configuration
data:
  domain: NZ # one of SA, ALPS or NZ
  training_experiment: ESD_pseudo_reality # ESD_pseudo_reality or Emulator_hist_future
  data_path: /bg/fast/aihydromet/cordexbench/
  var_target: pr # tasmax or pr 
  normalization: "mp1p1_input_m1p1log_target"   #'standardization', 'minmax', 'log', or None, or 'minus1_to_plus1' or "m1p1_log_target" or "mp1p1_input_m1p1log_target"
  num_workers: 4
  t_past: 0  # number of past time steps as input
  t_future: 0  # number of future time steps to predict

# Training configuration
training:
  batch_size: 32
  ensemble_size: 1
  epochs: 500
  batches_per_epoch: null  # set to null to use all data; otherwise set an integer value
  batches_per_validation: 5  # set to null to use all data; otherwise set an integer value
  n_critic: 2  # number of discriminator updates per generator update
  
  # Learning rate scheduler with warmup and exponential decay
  warmup_epochs: 5  # Number of epochs for linear warmup phase
  plateau_epochs: 30  # Number of epochs to maintain target LR before decay starts
  transition_epochs: 300  # Number of epochs over which to transition to decayed LR
  lr_decay_gamma: 0.98  # Exponential decay factor applied after plateau (lr *= gamma each epoch)
  warmup_start_lr: 1.0e-6  # Starting learning rate for warmup phase
  
  generator:
    learning_rate: 0.00005
    optimizer: "AdamW"
    scheduler: null
    beta1: 0.0
    beta2: 0.999
    weight_decay: 0.0001
  discriminator:
    learning_rate: 0.0005
    optimizer: "AdamW"
    scheduler: null
    beta1: 0.0
    beta2: 0.999
    weight_decay: 0.0001
  early_stopping: true
  patience: 10
  checkpoint_dir: "checkpoints"
  fss_loss: False # mainly for precip
  loss_weights:
    l1: 0.5
    mse: 1.0
    gan: 0.01
    fss: 0.0

# Model configuration
model:
  architecture: "spategan" # "diffusion_unet" or "spategan" or "deepesd"
  use_learnable_upsampler: false  # Use learnable conv-based upsampling instead of fixed bilinear
  
  # Generator architecture configurations
  generator:
    diffusion_unet:
      sample_size: [128, 128]
      in_channels: 16  # 15 input + 1 noise
      out_channels: 1
      layers_per_block: 1
      block_out_channels: [32, 64, 128,]
      down_block_types:
        - "DownBlock2D"
        - "DownBlock2D"
        - "DownBlock2D"
      up_block_types:
        - "UpBlock2D"
        - "UpBlock2D"
        - "UpBlock2D"
    spategan:
      filter_size: 96
      n_input_channels: 15
      n_output_channels: 1
      dropout_seed: 42
      dropout_ratio: 0.2
    deepesd:
      x_shape: [1,15,16,16]
      y_shape: [1,128,128]
      filters_last_conv: 1
  
  # Legacy fields for backward compatibility
  discriminator_architecture: "spategan" # "unet" or "spategan"
  filter_size: 96
  n_input_channels: 15
  n_output_channels: 1
  dropout_seed: 42
  dropout_ratio: 0.2

  # Discriminator architecture config
  discriminator:
    # High-resolution path channels (for target/prediction at 128x128)
    # Each entry creates one ResidualBlock2D with stride=2 (except first with stride=1)
    hr_channels: [128, 256, 256, 256, 128]
    # Low-resolution path channels (for coarse input at 16x16)
    # Each entry creates one ResidualBlock2D with stride=2 (except first with stride=1)
    lr_channels: [128, 128]
    # Combined path channels after concatenating hr and lr features
    # Each entry creates one ResidualBlock2D with stride=2
    combined_channels: [256]
    # Output head channels (final should be 1 for binary classification)
    # Creates Conv2d layers with LeakyReLU between (except last layer)
    output_channels: [64, 1]
    # Dropout rate for regularization (0.0 to disable)
    dropout: 0.3
    # Enable spectral normalization for stability
    spectral_norm: true

# Evaluation configuration
evaluation:
  metrics: ["rmse"]
  output_dir: "results"

# Logging configuration
logging:
  level: "INFO"
  log_dir: "logs"
  wandb: false # not implemented
  log_frequency: 1 # number of epochs between loss plots
  checkpoint_frequency: 20 # number of epochs between checkpoints
  map_frequency: 5 # number of epochs between plotting maps
  diagnostic_frequency: 5 # number of epochs between computing diagnostics